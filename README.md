# AcademicProject
Hand Sign Language Recognition Using Deep Learning
Hand gestures can be used as a form of communication in various applications. It can be used by people with a variety of disabilities, including hearing-impaired and speech-impaired to communicate and meet their basic needs. This study reveals the effectiveness of implementing Convolutional neural networks (CNN) in the development of hand sign language recognition systems for specific communication with the hearing impaired. According to the analysis, the correct accuracy rate of the CNN model for research purposes is 99.8466253286396%. Webcams can be added to the CNN model in an application format, just as they can be designed for practical use in future research work.![image](https://user-images.githubusercontent.com/93027932/138546564-2a8d3962-a2fa-4633-a615-7c04329b26b5.png)
